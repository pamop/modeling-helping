{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "simulate the two player farm game\n",
    "\n",
    "first, set up big config dictionary that specifies the game to be played\n",
    "\n",
    "jan 2023\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from random import randint\n",
    "import numpy as np\n",
    "import random\n",
    "import datetime # for limiting calculation to wall clock time\n",
    "import math\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "import farmgame\n",
    "from mcts import MCTS\n",
    "from agents import RandomPolicy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "red's turn!\n",
      "['Tomato00', 'Turnip01', 'Turnip00', 'Strawberry01', 'Strawberry00', 'Eggplant00', 'Tomato01', 'Turnip02', 'redpillow']\n",
      "red player picks turnip\n",
      "purple's turn!\n",
      "['Tomato00', 'Turnip01', 'Turnip00', 'Strawberry01', 'Strawberry00', 'Eggplant00', 'Tomato01', 'purplepillow']\n",
      "purple player picks tomato\n",
      "red's turn!\n",
      "['Turnip01', 'Turnip00', 'Strawberry01', 'Strawberry00', 'Eggplant00', 'Tomato01', 'box', 'redpillow']\n",
      "red player picks turnip\n",
      "purple's turn!\n",
      "['Turnip00', 'Strawberry01', 'Strawberry00', 'Eggplant00', 'Tomato01', 'box', 'purplepillow']\n",
      "purple player picks turnip\n",
      "red's turn!\n",
      "['Strawberry01', 'Strawberry00', 'Eggplant00', 'Tomato01', 'box', 'redpillow']\n",
      "red player picks box\n",
      "purple's turn!\n",
      "['Strawberry01', 'Strawberry00', 'Eggplant00', 'Tomato01', 'box', 'purplepillow']\n",
      "purple player picks eggplant\n",
      "red's turn!\n",
      "['Strawberry01', 'Strawberry00', 'Tomato01', 'redpillow']\n",
      "red player picks strawberry\n",
      "purple's turn!\n",
      "['Strawberry00', 'Tomato01', 'box', 'purplepillow']\n",
      "purple player picks pillow\n",
      "red's turn!\n",
      "['Strawberry00', 'Tomato01', 'box', 'redpillow']\n",
      "red player picks strawberry\n",
      "purple's turn!\n",
      "['Tomato01', 'box', 'purplepillow']\n",
      "purple player picks tomato\n",
      "red's turn!\n",
      "['box', 'redpillow']\n",
      "red player picks pillow\n",
      "purple's turn!\n",
      "['box', 'purplepillow']\n",
      "purple player picks box\n",
      "red's turn!\n",
      "['box', 'redpillow']\n",
      "red player picks box\n",
      "Red Reward:  (188, True)\n",
      "Purp Reward:  (176, True)\n"
     ]
    }
   ],
   "source": [
    "# practice randomly selecting an action from the legal list and then taking it\n",
    "TheFarm = farmgame.configure_game(layer=\"Items00\",resourceCond=\"even\",costCond=\"low\",visibilityCond=\"full\",redFirst=True)\n",
    "state = TheFarm\n",
    "\n",
    "done=False\n",
    "\n",
    "while not done:\n",
    "# for i in range(15):\n",
    "    currentplayer = state.players[state.turn]\n",
    "    print(currentplayer['name'] + \"'s turn!\")\n",
    "    # print(\"current backpack: \" + str(list(v['name'] for v in currentplayer['backpack']['contents'])))\n",
    "    # print(\"current farm items: \" + str(list(v['name'] for v in state.items)))\n",
    "    # print(\"current farm items: \" + str(list(v['status'] for v in state.items)))\n",
    "    actions = state.legal_actions()\n",
    "    if actions==[]:\n",
    "        action=None\n",
    "        print(currentplayer['name'] + \" passes turn. \")\n",
    "    else:\n",
    "        print(list(a.id for a in actions))\n",
    "        action = random.choice(actions) #actions[0]\n",
    "        print(currentplayer['name'] + \" player picks \" + action.name)\n",
    "    state = state.take_action(action,inplace=True) #pick first veg in list\n",
    "    rwd, done = state.reward(currentplayer['name'])\n",
    "\n",
    "print(\"Red Reward: \",state.reward('red'))\n",
    "print(\"Purp Reward: \",state.reward('purple'))\n",
    "    \n",
    "\n",
    "\n",
    "# action=random.choice(actions)\n",
    "# print(action.name)\n",
    "# new_state = state.take_action(action)\n",
    "# rwd, done = new_state.reward()\n",
    "# print(rwd, done)\n",
    "# new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "turn 0 complete\n",
      "turn 1 complete\n",
      "turn 2 complete\n",
      "turn 3 complete\n",
      "turn 4 complete\n",
      "turn 5 complete\n",
      "turn 6 complete\n",
      "turn 7 complete\n",
      "turn 8 complete\n",
      "turn 9 complete\n",
      "turn 10 complete\n",
      "turn 11 complete\n",
      "game 0 done\n",
      "turn 0 complete\n",
      "turn 1 complete\n",
      "turn 2 complete\n",
      "turn 3 complete\n",
      "turn 4 complete\n",
      "turn 5 complete\n",
      "turn 6 complete\n",
      "turn 7 complete\n",
      "turn 8 complete\n",
      "turn 9 complete\n",
      "game 1 done\n"
     ]
    }
   ],
   "source": [
    "# Creating a game from start - prototype for simulations w/ helping data output\n",
    "objectLayer = [\"Items00\",\"Items01\"] \n",
    "resourceCond = [\"even\"]\n",
    "costCond = [\"low\"] \n",
    "visibilityCond = [\"full\"]\n",
    "redFirst = [True]\n",
    "\n",
    "rC = resourceCond[0]\n",
    "cC = costCond[0]\n",
    "vC = visibilityCond[0]\n",
    "rF = redFirst[0]\n",
    "\n",
    "oL = objectLayer[0]\n",
    "gameNum = 0\n",
    "game_df = {\"gameNum\": [], \"player\": [], \"action\": [], \"veg_color\": [], \"steps\": [], \"helpful\": [], \"redRwd\": [], \"purpRwd\": []}\n",
    "for oL in objectLayer:\n",
    "    farm_config = farmgame.configure_game(layer=oL,resourceCond=rC,costCond=cC,visibilityCond=vC,redFirst=rF)\n",
    "    done = False\n",
    "    \n",
    "    # red\n",
    "    red_agent = MCTS(time=2., C=2, max_moves = 10, color=\"red\")\n",
    "    # red_agent = RandomPolicy(game)\n",
    "    # purple\n",
    "    purp_agent = MCTS(time=2., C=2, max_moves = 10, color=\"purple\")\n",
    "    # purp_agent = RandomPolicy(game)\n",
    "    \n",
    "    state = farm_config\n",
    "    # print(\"current farm items: \" + str(list(v.name for v in state.items if v.status==\"farm\")))\n",
    "    # print(\"current box: \" + str(list(v.name for v in state.farmbox.contents)))\n",
    "    t = 0\n",
    "    while not done:\n",
    "    \n",
    "        red_agent.update(state) \n",
    "        purp_agent.update(state)\n",
    "    \n",
    "        currentplayer = state.players[state.turn]\n",
    "        #print(currentplayer['name'] + \"'s turn!\")\n",
    "        #print(\"current backpack: \" + str(list(v.name for v in currentplayer['backpack']['contents'])))\n",
    "        #print(\"current farm items: \" + str(list(v.name for v in state.items)))\n",
    "        #print(\"current box: \" + str(list(v.name for v in state.farmbox.contents)))\n",
    "    \n",
    "        if currentplayer['name'] == \"red\":\n",
    "            action = red_agent.choose_action()\n",
    "        else:\n",
    "            action = purp_agent.choose_action()\n",
    "    \n",
    "        #find out if action is helpful or not\n",
    "        transition = farmgame.Transition(state,action)\n",
    "        helpful = transition.is_helping()\n",
    "    \n",
    "        #get steps taken\n",
    "        steps = state.get_steps(action)\n",
    "    \n",
    "        if action is None:\n",
    "            print(\"THIS SHOULdn't happen\")\n",
    "            #print(currentplayer['name'] + \" has no more moves.\")\n",
    "        else:\n",
    "            #print(currentplayer['name'] + \" player picks \" + action.name)\n",
    "            print(\"turn %s complete\"%(t))\n",
    "        state = state.take_action(action,inplace=True) #pick first veg in list\n",
    "        rwd, done = state.reward(currentplayer['name'])\n",
    "        t += 1\n",
    "        #add action data to dictionary\n",
    "        game_df[\"gameNum\"].append(gameNum)\n",
    "        game_df[\"player\"].append(currentplayer['name'])\n",
    "        game_df[\"action\"].append(action.name) \n",
    "        game_df[\"veg_color\"].append(action.color) \n",
    "        game_df[\"steps\"].append(steps)\n",
    "        game_df[\"helpful\"].append(helpful)\n",
    "\n",
    "    game_df[\"redRwd\"] += ([state.reward('red')[0]] * t)\n",
    "    game_df[\"purpRwd\"] += ([state.reward('purple')[0]] * t)\n",
    "\n",
    "    print(\"game %s done\"%(gameNum))\n",
    "    gameNum += 1\n",
    "\n",
    "    #print(\"Red Reward: \",state.reward('red')[0])\n",
    "    #print(\"Purp Reward: \",state.reward('purple')[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_game_outputs(game_df):\n",
    "    helping_event = game_df.helpful.sum()\n",
    "    steps = game_df.steps.sum()\n",
    "    helpful_steps = game_df.loc[game_df.helpful,\"steps\"].sum()\n",
    "    helped = helping_event > 0 \n",
    "    purpleHelpingEvents = game_df.loc[game_df.player == \"purple\",\"helpful\"].sum()\n",
    "    redHelpingEvents = game_df.loc[game_df.player == \"red\",\"helpful\"].sum()\n",
    "    purpleHelped = purpleHelpingEvents > 0 \n",
    "    redHelped = redHelpingEvents > 0 \n",
    "    purpleHelpfulSteps = game_df.loc[(game_df.player == \"purple\") & (game_df.helpful),\"steps\"].sum()\n",
    "    redHelpfulSteps = game_df.loc[(game_df.player == \"red\") & (game_df.helpful),\"steps\"].sum()\n",
    "    nRedVeg = (game_df.veg_color == \"red\").sum()\n",
    "    nPurpVeg = (game_df.veg_color == \"purple\").sum()\n",
    "    \n",
    "    agg_mets = pd.Series({\"helping_event\":helping_event, \"steps\": steps, \"helpful_steps\": helpful_steps, \"helped\": helped, \"purpleHelpingEvents\": purpleHelpingEvents,\n",
    "                          \"redHelpingEvents\": redHelpingEvents, \"purpleHelped\": purpleHelped, \"redHelped\": redHelped, \"purpleHelpfulSteps\": purpleHelpfulSteps, \n",
    "                          \"redHelpfulSteps\": redHelpfulSteps, \"nRedVeg\": nRedVeg, \"nPurpVeg\": nPurpVeg}) \n",
    "    return agg_mets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6r/gppxzrp57j9ggbttd9chp8cm0000gn/T/ipykernel_23408/4244742291.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  game_df_results = game_df.groupby(\"gameNum\").apply(aggregate_game_outputs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>helping_event</th>\n",
       "      <th>steps</th>\n",
       "      <th>helpful_steps</th>\n",
       "      <th>helped</th>\n",
       "      <th>purpleHelpingEvents</th>\n",
       "      <th>redHelpingEvents</th>\n",
       "      <th>purpleHelped</th>\n",
       "      <th>redHelped</th>\n",
       "      <th>purpleHelpfulSteps</th>\n",
       "      <th>redHelpfulSteps</th>\n",
       "      <th>nRedVeg</th>\n",
       "      <th>nPurpVeg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gameNum</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>106</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>75</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         helping_event  steps  helpful_steps  helped  purpleHelpingEvents  \\\n",
       "gameNum                                                                     \n",
       "0                    2    106             24    True                    1   \n",
       "1                    4     75             24    True                    2   \n",
       "\n",
       "         redHelpingEvents  purpleHelped  redHelped  purpleHelpfulSteps  \\\n",
       "gameNum                                                                  \n",
       "0                       1          True       True                  13   \n",
       "1                       2          True       True                  13   \n",
       "\n",
       "         redHelpfulSteps  nRedVeg  nPurpVeg  \n",
       "gameNum                                      \n",
       "0                     11        5         5  \n",
       "1                     11        4         4  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_df = pd.DataFrame(game_df)\n",
    "game_df_results = game_df.groupby(\"gameNum\").apply(aggregate_game_outputs)\n",
    "game_df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAME 0\n",
      "red player picks strawberry , helpful: False\n",
      "purple player picks turnip , helpful: False\n",
      "red player picks eggplant , helpful: True\n",
      "purple player picks tomato , helpful: True\n",
      "red player picks turnip , helpful: True\n",
      "purple player picks tomato , helpful: True\n",
      "red player picks strawberry , helpful: False\n",
      "purple player picks pillow , helpful: False\n",
      "red player picks pillow , helpful: False\n",
      "purple player picks turnip , helpful: False\n",
      "red player picks pillow , helpful: False\n",
      "purple player picks pillow , helpful: False\n",
      "red player picks box , helpful: False\n",
      "purple player picks pillow , helpful: False\n",
      "red player picks none , helpful: False\n",
      "purple player picks pillow , helpful: False\n",
      "red player picks none , helpful: False\n",
      "purple player picks box , helpful: False\n",
      "Red Reward:  156\n",
      "Purp Reward:  128\n",
      "GAME 1\n",
      "red player picks strawberry , helpful: False\n",
      "purple player picks tomato , helpful: True\n",
      "red player picks turnip , helpful: True\n",
      "purple player picks eggplant , helpful: False\n",
      "red player picks strawberry , helpful: False\n",
      "purple player picks turnip , helpful: False\n",
      "red player picks turnip , helpful: True\n",
      "purple player picks tomato , helpful: True\n",
      "red player picks box , helpful: False\n",
      "purple player picks box , helpful: False\n",
      "Red Reward:  172\n",
      "Purp Reward:  200\n",
      "GAME 2\n",
      "red player picks turnip , helpful: True\n",
      "purple player picks tomato , helpful: True\n",
      "red player picks strawberry , helpful: False\n",
      "purple player picks turnip , helpful: False\n",
      "red player picks strawberry , helpful: False\n",
      "purple player picks eggplant , helpful: False\n",
      "red player picks pillow , helpful: False\n",
      "purple player picks tomato , helpful: True\n",
      "red player picks turnip , helpful: True\n",
      "purple player picks box , helpful: False\n",
      "red player picks box , helpful: False\n",
      "Red Reward:  188\n",
      "Purp Reward:  188\n",
      "GAME 3\n",
      "red player picks strawberry , helpful: False\n",
      "purple player picks tomato , helpful: True\n",
      "red player picks turnip , helpful: True\n",
      "purple player picks turnip , helpful: False\n",
      "red player picks box , helpful: False\n",
      "purple player picks strawberry , helpful: True\n",
      "red player picks eggplant , helpful: True\n",
      "purple player picks tomato , helpful: True\n",
      "red player picks turnip , helpful: True\n",
      "purple player picks box , helpful: False\n",
      "red player picks box , helpful: False\n",
      "Red Reward:  160\n",
      "Purp Reward:  196\n"
     ]
    }
   ],
   "source": [
    "# compare random - random, mcts - random, random - mcts, mcts-mcts\n",
    "\n",
    "games = [{\"red_agent\": RandomPolicy(),\"purp_agent\": RandomPolicy()},\n",
    "        {\"red_agent\": MCTS(time=5., C=2, max_moves = 10),\"purp_agent\": RandomPolicy()},\n",
    "        {\"red_agent\": RandomPolicy(),\"purp_agent\": MCTS(time=5., C=2, max_moves = 10)},\n",
    "        {\"red_agent\": MCTS(time=5., C=2, max_moves = 10),\"purp_agent\": MCTS(time=5., C=2, max_moves = 10)},]\n",
    "rwds = []\n",
    "\n",
    "for i in range(len(games)):\n",
    "    print(\"GAME \"+str(i))\n",
    "    action_seq = []\n",
    "    state = farmgame.configure_game() # DEFAULT GAME\n",
    "    done = False\n",
    "\n",
    "    red_agent = games[i][\"red_agent\"]\n",
    "    purp_agent = games[i][\"purp_agent\"]\n",
    "    \n",
    "    while not done:\n",
    "\n",
    "        red_agent.update(state) \n",
    "        purp_agent.update(state)\n",
    "\n",
    "        currentplayer = state.players[state.turn]\n",
    "        # print(currentplayer['name'] + \"'s turn!\")\n",
    "        # print(\"current backpack: \" + str(list(v['name'] for v in currentplayer['backpack']['contents'])))\n",
    "        # print(\"current farm items: \" + str(list(v['name'] for v in state.items)))\n",
    "        # print(\"current box: \" + str(list(v['name'] for v in state.farmbox['contents'])))\n",
    "\n",
    "        if currentplayer['name'] == \"red\":\n",
    "            action = red_agent.choose_action()\n",
    "        else:\n",
    "            action = purp_agent.choose_action()\n",
    "\n",
    "        # actions = state.legal_actions(currentplayer)\n",
    "        # print(list(a.name for a in actions))\n",
    "        # action = actions[0]\n",
    "        transition = farmgame.Transition(state,action)\n",
    "        helpful = transition.is_helping()\n",
    "        if action is None:\n",
    "            print(\"THIS SHOULdn't happen\")\n",
    "            print(currentplayer['name'] + \" has no more moves.\")\n",
    "        else:\n",
    "            print(currentplayer['name'] + \" player picks \" + action.name, \", helpful: %s\"%(helpful))\n",
    "\n",
    "        state = state.take_action(action,inplace=True) #pick first veg in list\n",
    "        rwd, done = state.reward(currentplayer['name'])\n",
    "\n",
    "    print(\"Red Reward: \",state.reward('red')[0])\n",
    "    print(\"Purp Reward: \",state.reward('purple')[0])\n",
    "    rwds.append({\"red\":state.reward('red')[0],\"purple\":state.reward('purple')[0]})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C =  8\n",
      "Red Reward:  276\n",
      "Purp Reward:  288\n",
      "Red Reward:  220\n",
      "Purp Reward:  192\n",
      "Red Reward:  236\n",
      "Purp Reward:  200\n",
      "Red Reward:  168\n",
      "Purp Reward:  160\n",
      "Red Reward:  204\n",
      "Purp Reward:  248\n",
      "Red Reward:  276\n",
      "Purp Reward:  296\n",
      "Red Reward:  236\n",
      "Purp Reward:  184\n",
      "Red Reward:  212\n",
      "Purp Reward:  240\n",
      "Red Reward:  228\n",
      "Purp Reward:  248\n",
      "Red Reward:  164\n",
      "Purp Reward:  200\n",
      "C =  10\n",
      "Red Reward:  228\n",
      "Purp Reward:  160\n",
      "Red Reward:  244\n",
      "Purp Reward:  248\n",
      "Red Reward:  176\n",
      "Purp Reward:  196\n",
      "Red Reward:  164\n",
      "Purp Reward:  160\n",
      "Red Reward:  188\n",
      "Purp Reward:  204\n",
      "Red Reward:  228\n",
      "Purp Reward:  228\n",
      "Red Reward:  228\n",
      "Purp Reward:  176\n",
      "Red Reward:  204\n",
      "Purp Reward:  248\n",
      "Red Reward:  244\n",
      "Purp Reward:  208\n",
      "Red Reward:  236\n",
      "Purp Reward:  200\n",
      "C =  25\n",
      "Red Reward:  204\n",
      "Purp Reward:  240\n",
      "Red Reward:  156\n",
      "Purp Reward:  208\n",
      "Red Reward:  148\n",
      "Purp Reward:  220\n",
      "Red Reward:  148\n",
      "Purp Reward:  216\n",
      "Red Reward:  236\n",
      "Purp Reward:  200\n",
      "Red Reward:  164\n",
      "Purp Reward:  160\n",
      "Red Reward:  196\n",
      "Purp Reward:  176\n",
      "Red Reward:  204\n",
      "Purp Reward:  152\n",
      "Red Reward:  244\n",
      "Purp Reward:  160\n",
      "Red Reward:  244\n",
      "Purp Reward:  248\n",
      "C =  50\n",
      "Red Reward:  196\n",
      "Purp Reward:  264\n",
      "Red Reward:  188\n",
      "Purp Reward:  240\n",
      "Red Reward:  204\n",
      "Purp Reward:  256\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m     action \u001b[38;5;241m=\u001b[39m red_agent\u001b[38;5;241m.\u001b[39mchoose_action()\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m     action \u001b[38;5;241m=\u001b[39m purp_agent\u001b[38;5;241m.\u001b[39mchoose_action()\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# print(currentplayer['name'] + \" player picks \" + action['name'])\u001b[39;00m\n\u001b[1;32m     46\u001b[0m state \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mtake_action(action,inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m#pick first veg in list\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/NYU/3rd Sem NYU/Computational cognitive modeling/modeling-helping/modeling/mcts.py:77\u001b[0m, in \u001b[0;36mMCTS.choose_action\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     74\u001b[0m begin \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mutcnow()\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m (datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mutcnow() \u001b[38;5;241m-\u001b[39m begin) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalculation_time \u001b[38;5;129;01mand\u001b[39;00m games\u001b[38;5;241m<\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnsims:\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;66;03m# simulate games and store results in rewards and plays dictionaries.\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_simulation()\n\u001b[1;32m     78\u001b[0m     games\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;66;03m# # display number of calls of 'run_simulation' and the time elapsed\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/NYU/3rd Sem NYU/Computational cognitive modeling/modeling-helping/modeling/mcts.py:138\u001b[0m, in \u001b[0;36mMCTS.run_simulation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_moves):\n\u001b[1;32m    136\u001b[0m             legal \u001b[38;5;241m=\u001b[39m simstate\u001b[38;5;241m.\u001b[39mlegal_actions() \u001b[38;5;66;03m#self.game.legal_actions(states_copy) # get valid actions\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m             moves_states \u001b[38;5;241m=\u001b[39m [(a\u001b[38;5;241m.\u001b[39mid, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhash_and_store(simstate\u001b[38;5;241m.\u001b[39mtake_action(a,inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m legal]\n\u001b[1;32m    140\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(plays\u001b[38;5;241m.\u001b[39mget((player, S)) \u001b[38;5;28;01mfor\u001b[39;00m a, S \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28miter\u001b[39m(moves_states)):\n\u001b[1;32m    141\u001b[0m                 \u001b[38;5;66;03m# if we have statistics on all legal moves, use them.\u001b[39;00m\n\u001b[1;32m    142\u001b[0m                 \u001b[38;5;66;03m# upper confidence bound (UCB) algorithm\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m#                 print(\"UCB choice\")\u001b[39;00m\n\u001b[1;32m    144\u001b[0m                 log_total \u001b[38;5;241m=\u001b[39m log(\n\u001b[1;32m    145\u001b[0m                     \u001b[38;5;28msum\u001b[39m(plays[(player, S)] \u001b[38;5;28;01mfor\u001b[39;00m a, S \u001b[38;5;129;01min\u001b[39;00m moves_states)\n\u001b[1;32m    146\u001b[0m                 )\n",
      "File \u001b[0;32m~/Documents/NYU/3rd Sem NYU/Computational cognitive modeling/modeling-helping/modeling/mcts.py:138\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_moves):\n\u001b[1;32m    136\u001b[0m             legal \u001b[38;5;241m=\u001b[39m simstate\u001b[38;5;241m.\u001b[39mlegal_actions() \u001b[38;5;66;03m#self.game.legal_actions(states_copy) # get valid actions\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m             moves_states \u001b[38;5;241m=\u001b[39m [(a\u001b[38;5;241m.\u001b[39mid, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhash_and_store(simstate\u001b[38;5;241m.\u001b[39mtake_action(a,inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m legal]\n\u001b[1;32m    140\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(plays\u001b[38;5;241m.\u001b[39mget((player, S)) \u001b[38;5;28;01mfor\u001b[39;00m a, S \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28miter\u001b[39m(moves_states)):\n\u001b[1;32m    141\u001b[0m                 \u001b[38;5;66;03m# if we have statistics on all legal moves, use them.\u001b[39;00m\n\u001b[1;32m    142\u001b[0m                 \u001b[38;5;66;03m# upper confidence bound (UCB) algorithm\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m#                 print(\"UCB choice\")\u001b[39;00m\n\u001b[1;32m    144\u001b[0m                 log_total \u001b[38;5;241m=\u001b[39m log(\n\u001b[1;32m    145\u001b[0m                     \u001b[38;5;28msum\u001b[39m(plays[(player, S)] \u001b[38;5;28;01mfor\u001b[39;00m a, S \u001b[38;5;129;01min\u001b[39;00m moves_states)\n\u001b[1;32m    146\u001b[0m                 )\n",
      "File \u001b[0;32m~/Documents/NYU/3rd Sem NYU/Computational cognitive modeling/modeling-helping/modeling/mcts.py:228\u001b[0m, in \u001b[0;36mMCTS.hash_and_store\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhash_and_store\u001b[39m(\u001b[38;5;28mself\u001b[39m, s):\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# h = hash(s)\u001b[39;00m\n\u001b[0;32m--> 228\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mhash\u001b[39m(s))\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfarmstatehash[h] \u001b[38;5;241m=\u001b[39m s\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m h\n",
      "File \u001b[0;32m~/Documents/NYU/3rd Sem NYU/Computational cognitive modeling/modeling-helping/modeling/farmgame.py:445\u001b[0m, in \u001b[0;36mFarm.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;66;03m# print(hash(tuple(self)))\u001b[39;00m\n\u001b[0;32m--> 445\u001b[0m     shash \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mhash\u001b[39m(\u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m))\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;66;03m# shashkey = str(shash)\u001b[39;00m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;66;03m# # with shelve.open('farmstatehash') as shelf:\u001b[39;00m\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;66;03m# #     if not shashkey in shelf:\u001b[39;00m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;66;03m# #         # we need to store this state as it has never been hashed before\u001b[39;00m\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;66;03m# #         shelf[shashkey]= self #tuple(self) # CAN I STORE THE ACTUAL OBJECT INSTEAD OF TUPSTATE???\u001b[39;00m\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;66;03m# farmstatehash[shashkey]=self\u001b[39;00m\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m shash\n",
      "File \u001b[0;32m~/Documents/NYU/3rd Sem NYU/Computational cognitive modeling/modeling-helping/modeling/farmgame.py:399\u001b[0m, in \u001b[0;36mFarm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 399\u001b[0m     state \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\n\u001b[1;32m    400\u001b[0m         \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m    401\u001b[0m     )  \u001b[38;5;66;03m# otherwise it turns the items themselves into tuples!\u001b[39;00m\n\u001b[1;32m    402\u001b[0m     props \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    403\u001b[0m         state\u001b[38;5;241m.\u001b[39mredplayer,\n\u001b[1;32m    404\u001b[0m         state\u001b[38;5;241m.\u001b[39mpurpleplayer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    410\u001b[0m         state\u001b[38;5;241m.\u001b[39mturn,\n\u001b[1;32m    411\u001b[0m     ]\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(props)):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Finance/lib/python3.11/copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m _reconstruct(x, memo, \u001b[38;5;241m*\u001b[39mrv)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Finance/lib/python3.11/copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[0;32m--> 271\u001b[0m         state \u001b[38;5;241m=\u001b[39m deepcopy(state, memo)\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    273\u001b[0m         y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Finance/lib/python3.11/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m copier(x, memo)\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Finance/lib/python3.11/copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m deepcopy(value, memo)\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Finance/lib/python3.11/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m copier(x, memo)\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Finance/lib/python3.11/copy.py:206\u001b[0m, in \u001b[0;36m_deepcopy_list\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    204\u001b[0m append \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mappend\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x:\n\u001b[0;32m--> 206\u001b[0m     append(deepcopy(a, memo))\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Finance/lib/python3.11/copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m _reconstruct(x, memo, \u001b[38;5;241m*\u001b[39mrv)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Finance/lib/python3.11/copy.py:272\u001b[0m, in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m    271\u001b[0m     state \u001b[38;5;241m=\u001b[39m deepcopy(state, memo)\n\u001b[0;32m--> 272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    273\u001b[0m     y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# now let's compare the performance of different C\n",
    "\n",
    "storestates = []\n",
    "storeactions = []\n",
    "storerewards_red = []\n",
    "storerewards_purp = []\n",
    "cs = [8,10,25,50,100,150]\n",
    "\n",
    "n_reps = 10\n",
    "all_rwds_c_r = []\n",
    "all_rwds_c_p = []\n",
    "\n",
    "for c in cs:\n",
    "    print(\"C = \", c)\n",
    "    storerewards_red = []\n",
    "    storerewards_purp = []\n",
    "\n",
    "    for i in range(n_reps):\n",
    "    \n",
    "        state = farmgame.configure_game(layer=\"Items00\",resourceCond=\"even\",costCond=\"low\",visibilityCond=\"full\",redFirst=True)\n",
    "        done = False\n",
    "\n",
    "        # red\n",
    "        red_agent = MCTS(time=5., C=c, max_moves = 10, color=\"red\") #, verbose=True)\n",
    "\n",
    "        # purple\n",
    "        purp_agent = MCTS(time=5., C=c, max_moves = 10, color=\"purple\")\n",
    "\n",
    "        action_seq = []\n",
    "\n",
    "\n",
    "        while not done:\n",
    "\n",
    "            red_agent.update(state) \n",
    "            purp_agent.update(state)\n",
    "\n",
    "            currentplayer = state.players[state.turn]\n",
    "\n",
    "            if currentplayer['name'] == \"red\":\n",
    "                action = red_agent.choose_action()\n",
    "            else:\n",
    "                action = purp_agent.choose_action()\n",
    "\n",
    "            # print(currentplayer['name'] + \" player picks \" + action['name'])\n",
    "            \n",
    "            state = state.take_action(action,inplace=True) #pick first veg in list\n",
    "            rwd, done = state.reward(currentplayer['name'])\n",
    "\n",
    "            action_seq.append(action)\n",
    "\n",
    "\n",
    "        print(\"Red Reward: \",state.reward('red')[0])\n",
    "        print(\"Purp Reward: \",state.reward('purple')[0])\n",
    "        \n",
    "        storestates.append([red_agent.states])\n",
    "        storeactions.append([action_seq])\n",
    "        storerewards_red.append(state.reward('red')[0])\n",
    "        storerewards_purp.append(state.reward('purple')[0])\n",
    "\n",
    "    all_rwds_c_r.append(storerewards_red)\n",
    "    all_rwds_c_p.append(storerewards_purp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cashmoney_r = [i for (i,a) in storerewards_red]\n",
    "# cashmoney_p = [i for (i,a) in storerewards_purp]\n",
    "\n",
    "# plt.plot(cs,storerewards_red,'o-',color=\"red\")\n",
    "# plt.plot(cs,storerewards_purp,'o-',color=\"purple\")\n",
    "\n",
    "plt.plot(cs,np.mean(all_rwds_c_r),yerr=np.std(all_rwds_c_r),color=\"red\")\n",
    "plt.plot(cs,np.mean(all_rwds_c_p),yerr=np.std(all_rwds_c_p),color=\"purple\")\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"reward\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's compare the performance of different computation times\n",
    "\n",
    "storetstates = []\n",
    "storetactions = []\n",
    "\n",
    "# 1min, 2min, 3min, 4min, 5min, 6min per game approx\n",
    "times = [0.1,0.5,1,2,5,10,15,20,25,30]\n",
    "\n",
    "# set c as desired\n",
    "c=100\n",
    "\n",
    "# 10*(1 + 2 + 3 + 4 + 5 + 6) = 210 min approx (~3.5 hours)\n",
    "n_reps = 10\n",
    "all_rwds_r = []\n",
    "all_rwds_p = []\n",
    "\n",
    "for t in times:\n",
    "    print(\"Computation time = \", t)\n",
    "    storetrewards_red = []\n",
    "    storetrewards_purp = []\n",
    "\n",
    "    for i in range(n_reps):\n",
    "\n",
    "        # Initialize the tamagotchi\n",
    "        state = farmgame.configure_game(layer=\"Items00\",resourceCond=\"even\",costCond=\"low\",visibilityCond=\"full\",redFirst=True)\n",
    "        done = False\n",
    "\n",
    "         # red\n",
    "        red_agent = MCTS(time=t, C=c, max_moves = 10, color=\"red\")\n",
    "\n",
    "        # purple\n",
    "        purp_agent = MCTS(time=t, C=c, max_moves = 10, color=\"purple\")\n",
    "\n",
    "        action_seq = []\n",
    "        \n",
    "        while not done:\n",
    "            red_agent.update(state) \n",
    "            purp_agent.update(state)\n",
    "\n",
    "            currentplayer = state.players[state.turn]\n",
    "\n",
    "            if currentplayer['name'] == \"red\":\n",
    "                action = red_agent.choose_action()\n",
    "            else:\n",
    "                action = purp_agent.choose_action()\n",
    "            \n",
    "            state = state.take_action(action,inplace=True) #pick first veg in list\n",
    "            rwd, done = state.reward(currentplayer['name'])\n",
    "\n",
    "            action_seq.append(action)\n",
    "\n",
    "        print(\"Red Reward: \",state.reward('red')[0])\n",
    "        print(\"Purp Reward: \",state.reward('purple')[0])\n",
    "        \n",
    "        storetstates.append([red_agent.states])\n",
    "        storetactions.append([action_seq])\n",
    "        storetrewards_red.append(state.reward('red')[0])\n",
    "        storetrewards_purp.append(state.reward('purple')[0])\n",
    "\n",
    "    all_rwds_r.append(storetrewards_red)\n",
    "    all_rwds_p.append(storetrewards_purp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_rwds_r)\n",
    "print(np.shape(all_rwds_r))\n",
    "np.mean(all_rwds_r,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot rwd vs comp time\n",
    "\n",
    "plt.errorbar(times,np.mean(all_rwds_r,axis=1),yerr=np.std(all_rwds_r),color=\"red\")\n",
    "plt.errorbar(times,np.mean(all_rwds_p,axis=1),yerr=np.std(all_rwds_p),color=\"purple\")\n",
    "plt.xlabel(\"Computation time limit (s)\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storelstates = []\n",
    "storelactions = []\n",
    "storelrewards_red = []\n",
    "storelrewards_purp = []\n",
    "layers = [\"Items00\",\"Items01\",\"Items02\",\"Items03\",\"Items04\",\"Items05\",\"Items06\",\"Items07\",\"Items08\",\"Items09\",\"Items10\",\"Items11\"]\n",
    "\n",
    "for l in layers:\n",
    "    print(\"Layer = \", l)\n",
    "    \n",
    "    # Initialize the tamagotchi\n",
    "    state = farmgame.configure_game(layer = l)\n",
    "    game = farmgame.FarmGame()\n",
    "    done = False\n",
    "\n",
    "    # red\n",
    "    red_agent = MCTS(game, time=2., C=1, max_moves = 20)\n",
    "\n",
    "    # purple\n",
    "    purp_agent = MCTS(game, time=2., C=1, max_moves = 20)\n",
    "\n",
    "    action_seq = []\n",
    "    \n",
    "    while not done:\n",
    "        red_agent.update(state) \n",
    "        purp_agent.update(state)\n",
    "\n",
    "        currentplayer = state.players[state.turn]\n",
    "        # print(\"*** \" + currentplayer.name + \"'s turn! ***\")\n",
    "        # print(\"current farm items: \" + str(list(v.name for v in state.items if v.status==\"farm\")))\n",
    "        # print(\"current backpack: \" + str(list(v.name for v in currentplayer.backpack.contents)))\n",
    "        # print(\"current box: \" + str(list(v.name for v in state.farmbox.contents)))\n",
    "\n",
    "        if currentplayer.name == \"red\":\n",
    "            action = red_agent.choose_action()\n",
    "        else:\n",
    "            action = purp_agent.choose_action()\n",
    "\n",
    "        action_seq.append(action)\n",
    "\n",
    "        #find out if chosen action is helpful\n",
    "        transition = farmgame.Transition(state,action)\n",
    "        helpful = transition.is_helping()\n",
    "\n",
    "        #get number of steps\n",
    "        steps = state.get_steps(action)\n",
    "        print(helpful, steps)\n",
    "\n",
    "        if action is None:\n",
    "            print(currentplayer.name + \" has no more moves.\")\n",
    "        else:\n",
    "            print(currentplayer.name + \" player picks \" + action.name)\n",
    "        state = state.take_action(action,inplace=True) #pick first veg in list\n",
    "        rwd, done = state.reward(currentplayer.name)\n",
    "\n",
    "    print(\"Red Reward: \",game.reward(red_agent.states,'red'))\n",
    "    print(\"Purp Reward: \",game.reward(purp_agent.states,'purple'))\n",
    "    \n",
    "    storelstates.append([red_agent.states])\n",
    "    storelactions.append([action_seq])\n",
    "    storelrewards_red.append(game.reward(red_agent.states,'red'))\n",
    "    storelrewards_purp.append(game.reward(purp_agent.states,'purple'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(storelrewards_red)\n",
    "print(storelrewards_purp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "baf2bf159e7aee4be20dfb0978184648745e2c3fd1ea51978f5e222ff674cedf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
